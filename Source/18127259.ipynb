{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Đồ án 4: Phân lớp văn bản với kĩ thuật bình phương tối tiểu</h1>\n",
    "\n",
    "Họ và tên | MSSV | Lớp\n",
    "----------|------|------\n",
    "Kiều Công Hậu | 18127259 | 18CLC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T CHANGE this part: import libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " train.json valid.json 1\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE this part: read data path\n",
    "train_set_path, valid_set_path, random_number = input().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Xử lý dữ liệu văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đọc dữ liệu của 1 cột thuộc tính, trong đó:\n",
    "- `data_path`: (str) đường dẫn của tập dữ liệu\n",
    "- `attribute`: (str) thuộc tính mà ta muốn đọc (ví dụ: reviewText, overall,...)\n",
    "\n",
    "Cụ thể, em đã dùng hàm `json.load()` để đọc file .json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc file dữ liệu ứng với thuộc tính tương ứng.\n",
    "def read_data(data_path, attribute):\n",
    "    f = open(data_path)\n",
    "    data = json.load(f)\n",
    "    attribute_data = np.array([data[i][attribute] for i in range(len(data))])\n",
    "    f.close()\n",
    "    return attribute_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiền xử lý dữ liệu của một văn bản, trong đó:\n",
    "- `text`: (str) nội dung của văn bản mà ta muốn xử lý.\n",
    "\n",
    "Cụ thể, em đã xài các hàm sau để xử lý:\n",
    "- Chuyển tất cả thành chữ thường: `lower()`\n",
    "- Chuyển số thành ký tự `'num'` (int lẫn float): `isnumeric()` kết hợp với `replace()`\n",
    "- Tách từ: `word_tokenize()`\n",
    "- Loại bỏ stopwords: `stopwords.words('english')`\n",
    "- Stemming: `PorterStemmer().stem()`\n",
    "\n",
    "Từ `'unk'` cũng được thêm vào vocab. Cho nên, tất cả các từ out-of-vocab đều được đổi thành `'unk'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiền xử lý dữ liệu một văn bản.\n",
    "def preprocess(text):\n",
    "    filtered_word_list = []\n",
    "    word_list = word_tokenize(text.lower())\n",
    "    stop_word_list = stopwords.words('english')\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word.replace('.', '', 1).isnumeric():\n",
    "            word = 'num'\n",
    "        if word not in stop_word_list:\n",
    "            filtered_word_list.append(ps.stem(word))\n",
    "            \n",
    "    return np.array(filtered_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm dưới đây chỉ đơn giản là tiền xử lý nhiều văn bản và trả về một list các văn bản đã được tiền xử lý, trong đó:\n",
    "- `text_data`: list các văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiền xử lý dữ liệu nhiều văn bản.\n",
    "def preprocess_data(text_data):\n",
    "    return np.array([preprocess(reviewText) for reviewText in text_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng vocab dựa vào bộ dữ liệu reviewText đã qua tiền xử lý, trong đó:\n",
    "- `pre_reviewText_data`: list các văn bản review đã qua tiền xử lý.\n",
    "\n",
    "Cụ thể, vocab có cấu trúc dữ liệu dạng `dict`, key là từ, value tần số xuất hiện của từ đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng vocab dựa trên dữ liệu đã được tiền xử lý.\n",
    "def generate_vocab(pre_reviewText_data):\n",
    "    vocab = {}\n",
    "    for pre_reviewText in pre_reviewText_data:\n",
    "        for word in pre_reviewText:\n",
    "            vocab[word] = 0\n",
    "    vocab['unk'] = 0\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dụng ma trận histogram dựa vào list các văn bản review đã qua xử lý và vocab, trong đó:\n",
    "- `pre_reviewText_data`: list các văn bản review đã qua tiền xử lý.\n",
    "- `vocab`: bộ từ vựng.\n",
    "\n",
    "Ý tưởng, tạo các `count vector` trước, sau đó chuyển `count vector` thành các `histogram vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng bộ ma trận nhúng của văn bản.\n",
    "def generate_histogram_matrix(pre_reviewText_data, vocab):\n",
    "    count_matrix = [vocab.copy() for _ in range(pre_reviewText_data.shape[0])]\n",
    "    for i in range(pre_reviewText_data.shape[0]):\n",
    "        for word in pre_reviewText_data[i]:\n",
    "            if word not in vocab:\n",
    "                word = 'unk'\n",
    "            count_matrix[i][word] += 1\n",
    "\n",
    "    count_matrix = np.array([np.array([count_vector[word] for word in count_vector]) for count_vector in count_matrix])\n",
    "    histogram_matrix = count_matrix / (count_matrix @ np.ones(count_matrix.shape[1]))[:, np.newaxis]\n",
    "    \n",
    "    return histogram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuẩn hóa danh sách các nhãn thành danh sách các vector, trong đó:\n",
    "- `overall_data`: list các đánh giá dựa trên văn bản review tương ứng.\n",
    "\n",
    "Cụ thể, kết quả trả về của hàm này là một ma trận có kích thước `(n, 5)` với `n` là số lượng văn bản của tập train và `5` là số loại đánh giá {1, 2, 3, 4, 5}. Giả sử, một vản bản có `overall` là 3 thì vector tương ứng sẽ là `(0, 0, 1, 0, 0)`. Tổng quát, nếu `overall` là `i` thì phần tử tại index `i - 1` sẽ được bật lên 1, còn lại là 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa nhãn thành vector.\n",
    "def generate_label_matrix(overall_data):\n",
    "    label_matrix = np.zeros((overall_data.shape[0], 5))\n",
    "    for i in range(overall_data.shape[0]):\n",
    "        label_matrix[i][int(overall_data[i]) - 1] = 1\n",
    "    return label_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Sử dụng mô hình hồi quy tuyến tính dùng bình phương tối tiểu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng mô hình hồi quy tuyến tính, trong đó:\n",
    "- `pre_train_reviewText_data`: list các văn bản review đã qua tiền xử lý của tập train.\n",
    "- `vocab`: bộ từ vựng từ tập train.\n",
    "- `train_overall_data`: list các đánh giá tương ứng với văn bản của tập train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình hồi quy tuyến tính dựa trên tập huấn luyện.\n",
    "def linear_regression(pre_train_reviewText_data, vocab, train_overall_data):\n",
    "    histogram_matrix = generate_histogram_matrix(pre_train_reviewText_data, vocab)\n",
    "    label_matrix = generate_label_matrix(train_overall_data)\n",
    "    x_hat = np.linalg.pinv(np.concatenate((np.ones((histogram_matrix.shape[0], 1)), histogram_matrix), axis=1)) @ label_matrix\n",
    "    return x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Sử dụng độ chính xác để đánh giá mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa vào mô hình đã xây dựng (x_hat), ta dễ dàng dự đoán được nhãn của các văn bản review cần kiểm thử thông qua công thức `y = A @ x_hat`. Sau đó đếm xem có bao nhiêu nhãn dự đoán đúng thông qua mô hình trên. Độ chính xác của mô hình được đánh giá bằng công thức dưới đây:\n",
    "$$ acc = \\frac{\\sum(right)}{\\sum(total)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá độ chính xác của mô hình.\n",
    "def calc_accuracy(x_hat, vocab, pre_valid_reviewText_data, valid_overall_data):\n",
    "    valid_histogram_matrix = generate_histogram_matrix(pre_valid_reviewText_data, vocab)\n",
    "    y = np.concatenate((np.ones((valid_histogram_matrix.shape[0], 1)), valid_histogram_matrix), axis=1) @ x_hat\n",
    "    predicted_label_data = np.argmax(scipy.special.softmax(y, axis=1), axis=1) + 1\n",
    "    valid_count = 0\n",
    "    for i in range(valid_overall_data.shape[0]):\n",
    "        if valid_overall_data[i] == predicted_label_data[i]:\n",
    "            valid_count += 1\n",
    "    return valid_count / valid_overall_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Báo cáo tổng kết:** với 2 tập dataset `train.json` và `valid.json` trong file mô tả yêu cầu thì độ chính xác của mô hình M2 là 0.52 (thời gian chạy khoảng 60s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['strong', 'would', 'like', 'peavey', 'mike', \"'ll\", 'price', '.']\n",
      "M2 - 0.52\n"
     ]
    }
   ],
   "source": [
    "# Read data.\n",
    "train_reviewText_data = read_data(train_set_path, 'reviewText')\n",
    "train_overall_data = read_data(train_set_path, 'overall')\n",
    "\n",
    "valid_reviewText_data = read_data(valid_set_path, 'reviewText')\n",
    "valid_overall_data = read_data(valid_set_path, 'overall')\n",
    "\n",
    "# Preprocess.\n",
    "pre_train_reviewText_data = preprocess_data(train_reviewText_data)\n",
    "pre_valid_reviewText_data = preprocess_data(valid_reviewText_data)\n",
    "\n",
    "# Vocab\n",
    "vocab = generate_vocab(pre_train_reviewText_data)\n",
    "\n",
    "# Linear regression.\n",
    "x_hat = linear_regression(pre_train_reviewText_data, vocab, train_overall_data)\n",
    "\n",
    "# Accuracy.\n",
    "accuracy = calc_accuracy(x_hat, vocab, pre_valid_reviewText_data, valid_overall_data)\n",
    "\n",
    "# Output\n",
    "print(list(pre_valid_reviewText_data[int(random_number)]))\n",
    "print(\"M2 - \", end='')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
